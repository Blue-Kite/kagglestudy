{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T14:51:45.948847Z","iopub.execute_input":"2022-01-11T14:51:45.949212Z","iopub.status.idle":"2022-01-11T14:51:45.982636Z","shell.execute_reply.started":"2022-01-11T14:51:45.949127Z","shell.execute_reply":"2022-01-11T14:51:45.981781Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pathlib\nimport imageio\nimport numpy as np\n\ntraining_paths = pathlib.Path('../input/stage1_train').glob('*/images/*.png')\ntraining_sorted = sorted([x for x in training_paths])\nim_path = training_sorted[45]\nim = imageio.imread(str(im_path))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:51:45.984306Z","iopub.execute_input":"2022-01-11T14:51:45.984569Z","iopub.status.idle":"2022-01-11T14:51:46.080139Z","shell.execute_reply.started":"2022-01-11T14:51:45.984534Z","shell.execute_reply":"2022-01-11T14:51:46.079221Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Print the image dimensions\nprint('Original image shape: {}'.format(im.shape))\n\n# Coerce the image into grayscale format (if not already)\nfrom skimage.color import rgb2gray\nim_gray = rgb2gray(im)\nprint('New image shape: {}'.format(im_gray.shape))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.filters import threshold_otsu\nthresh_val = threshold_otsu(im_gray)\nmask = np.where(im_gray > thresh_val, 1, 0)\n\n# Make sure the larger portion of the mask is considered background\nif np.sum(mask==0) < np.sum(mask==1):\n    mask = np.where(mask, 0, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import ndimage\nlabels, nlabels = ndimage.label(mask)\n\nlabel_arrays = []\nfor label_num in range(1, nlabels+1):\n    label_mask = np.where(labels == label_num, 1, 0)\n    label_arrays.append(label_mask)\n\nprint('There are {} separate components / objects detected.'.format(nlabels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for label_ind, label_coords in enumerate(ndimage.find_objects(labels)):\n    cell = im_gray[label_coords]\n    \n    # Check if the label size is too small\n    if np.product(cell.shape) < 10: \n        print('Label {} is too small! Setting to 0.'.format(label_ind))\n        mask = np.where(labels==label_ind+1, 0, mask)\n\n# Regenerate the labels\nlabels, nlabels = ndimage.label(mask)\nprint('There are now {} separate components / objects detected.'.format(nlabels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"two_cell_indices = ndimage.find_objects(labels)[1]\ncell_mask = mask[two_cell_indices]\ncell_mask_opened = ndimage.binary_opening(cell_mask, iterations=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encoding(x):\n    '''\n    x: numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns run length as list\n    '''\n    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return \" \".join([str(i) for i in run_lengths])\n\nprint('RLE Encoding for the current mask is: {}'.format(rle_encoding(label_mask)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef analyze_image(im_path):\n    '''\n    Take an image_path (pathlib.Path object), preprocess and label it, extract the RLE strings \n    and dump it into a Pandas DataFrame.\n    '''\n    # Read in data and convert to grayscale\n    im_id = im_path.parts[-3]\n    im = imageio.imread(str(im_path))\n    im_gray = rgb2gray(im)\n    \n    # Mask out background and extract connected objects\n    thresh_val = threshold_otsu(im_gray)\n    mask = np.where(im_gray > thresh_val, 1, 0)\n    if np.sum(mask==0) < np.sum(mask==1):\n        mask = np.where(mask, 0, 1)    \n        labels, nlabels = ndimage.label(mask)\n    labels, nlabels = ndimage.label(mask)\n    \n    # Loop through labels and add each to a DataFrame\n    im_df = pd.DataFrame()\n    for label_num in range(1, nlabels+1):\n        label_mask = np.where(labels == label_num, 1, 0)\n        if label_mask.flatten().sum() > 10:\n            rle = rle_encoding(label_mask)\n            s = pd.Series({'ImageId': im_id, 'EncodedPixels': rle})\n            im_df = im_df.append(s, ignore_index=True)\n    \n    return im_df\n\n\ndef analyze_list_of_images(im_path_list):\n    '''\n    Takes a list of image paths (pathlib.Path objects), analyzes each,\n    and returns a submission-ready DataFrame.'''\n    all_df = pd.DataFrame()\n    for im_path in im_path_list:\n        im_df = analyze_image(im_path)\n        all_df = all_df.append(im_df, ignore_index=True)\n    \n    return all_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing = pathlib.Path('../input/stage1_test/').glob('*/images/*.png')\ndf = analyze_list_of_images(list(testing))\ndf.to_csv('submission.csv', index=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}